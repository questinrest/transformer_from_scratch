{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3352c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6f7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters to define first\n",
    "\n",
    "# X is an input matrix, having shape (seq_len, dmodel)\n",
    "# Wq is query trainable, having shape (dmodel, dk)\n",
    "# Wk is key trainable, having shape (dmodel, dk)\n",
    "# Wv is value trainable, having shape (dmodel, dk), dv = dk\n",
    "# Wo trainable, having shape (dk*h, dmodel)\n",
    "# Q = X @ Wq, shape (seq_len, dk)\n",
    "# K = X @ Wk, shape (seq_len, dk)\n",
    "# V  = X @ Wv, shape (seq_len, dk), dk= dv\n",
    "# A = Attention(Q, K.t()), shape (seq_len, seq_len) where Attention(Q, K.t()) = (Q @ K.t())/sqrt(dk)\n",
    "# Masking -- shape(seq_len, seq_len)\n",
    "# then  Softmax(A), shape (seq_len, seq_len)\n",
    "# second_last => Softmax(A) @ V, shape (seq_len, dk)\n",
    "# lastly,  (Softmax(A) @ V) @ Wo, shape (seq_len, dmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbec753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([\n",
    "    [0.72,0.45,0.31], # Dream\n",
    "    [0.75,0.20,0.55], # big\n",
    "    [0.30,0.80,0.40], # and\n",
    "    [0.85,0.35,0.60], # work\n",
    "    [0.55,0.15,0.75], # for\n",
    "    [0.25,0.20,0.85] # it\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37ef32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## implementation of Scaled Dot Product Attention using Class\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CausalAttentionSingleHead(nn.Module):\n",
    "    def __init__(self, dk, dmodel, dropout):\n",
    "        super(CausalAttentionSingleHead, self).__init__()\n",
    "        self.dk = dk\n",
    "        self.dmodel = dmodel\n",
    "        self.weight_query = nn.Linear(self.dmodel, self.dk)\n",
    "        self.weight_value = nn.Linear(self.dmodel, self.dk)\n",
    "        self.weight_key = nn.Linear(self.dmodel, self.dk)\n",
    "        ## defining Softmax\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        ## defining dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        # calculating the Query, Key and Value tensors\n",
    "        Q = self.weight_query(X)\n",
    "        K = self.weight_key(X)\n",
    "        V = self.weight_value(X)\n",
    "        # calculating the attention score and scaling\n",
    "        attn_score = (Q @ K.t())/( self.dk**0.5)\n",
    "        # applying masking, first defining mask then applying\n",
    "        mask = torch.triu(torch.ones((X.shape[0], X.shape[0])), diagonal=1)\n",
    "        masked_attn_score = attn_score.masked_fill(mask.bool(), -torch.inf)\n",
    "        # calculating the Softmax of the attn_score and adding dropouts\n",
    "        A = self.dropout(self.softmax(masked_attn_score))\n",
    "        # multiplying A with V\n",
    "        return A @ V, A\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e58b39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = CausalAttentionSingleHead(dk = 2, dropout=0.2, dmodel= X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f10d168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2055, 1.1526],\n",
       "         [0.2465, 1.2458],\n",
       "         [0.2133, 1.1259],\n",
       "         [0.1262, 0.6373],\n",
       "         [0.1801, 0.9241],\n",
       "         [0.1382, 0.6207]], grad_fn=<MmBackward0>),\n",
       " tensor([[1.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6336, 0.6164, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4398, 0.4349, 0.3753, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3227, 0.3166, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2613, 0.2496, 0.2490, 0.0000, 0.2349, 0.0000],\n",
       "         [0.2226, 0.0000, 0.0000, 0.2145, 0.0000, 0.1886]],\n",
       "        grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd46dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec82888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9f180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436e3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = torch.tensor([\n",
    "    [0.72,0.45,0.31], # Dream\n",
    "    [0.75,0.20,0.55], # big\n",
    "    [0.30,0.80,0.40], # and\n",
    "    [0.85,0.35,0.60], # work\n",
    "    [0.55,0.15,0.75], # for\n",
    "    [0.25,0.20,0.85] # it\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7274d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.attention import CausalAttentionSingleHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdbeca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_attn = CausalAttentionSingleHead(dk = 512, dmodel = 3, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd56d800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2411, -0.9794,  1.2128,  ...,  0.5255, -0.1772, -0.1950],\n",
       "        [-0.1152, -0.4679,  0.5794,  ...,  0.2511, -0.0847, -0.0931],\n",
       "        [-0.3026, -0.9404,  1.1810,  ...,  0.6016, -0.1390, -0.2028],\n",
       "        [-0.1690, -0.4631,  0.6101,  ...,  0.3045, -0.0395, -0.1343],\n",
       "        [-0.2308, -1.0082,  1.1772,  ...,  0.6957, -0.0901, -0.1754],\n",
       "        [-0.2192, -0.7978,  0.9430,  ...,  0.5812, -0.0740, -0.1420]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_attn.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c5688",
   "metadata": {},
   "source": [
    "## Masked MultiHead Attention Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc45823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133b509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, dmodel, dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h = h\n",
    "        self.dmodel = dmodel\n",
    "        assert self.dmodel % self.h == 0, \"head and dmodel configuration failed\"\n",
    "        self.dk = self.dmodel // self.h\n",
    "        self.weight_query = nn.Linear(dmodel, dmodel)\n",
    "        self.weight_key = nn.Linear(dmodel, dmodel)\n",
    "        self.weight_value = nn.Linear(dmodel, dmodel)\n",
    "        self.w_o = nn.Linear(dmodel, dmodel)\n",
    "        # softmax\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        # drop out\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        seq_len = X.shape[0]\n",
    "        Q = self.weight_query(X)\n",
    "        K = self.weight_key(X)\n",
    "        V = self.weight_value(X)\n",
    "        Q_head = torch.permute(torch.reshape(Q, shape=(seq_len, self.h, self.dk)), dims= (1, 0, 2))\n",
    "        K_head = torch.permute(torch.reshape(K, shape=(seq_len, self.h, self.dk)), dims= (1, 0, 2))\n",
    "        V_head = torch.permute(torch.reshape(V, shape=(seq_len, self.h, self.dk)), dims= (1, 0, 2))\n",
    "        # calculating attention score and scaling\n",
    "        attn_score = (torch.matmul(Q_head, K_head.transpose(-1,-2)))/(math.sqrt(self.dk))\n",
    "        # applying masking\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "        attn_score_masked = attn_score.masked_fill(mask.bool(), -torch.inf)\n",
    "        # applying softmax\n",
    "        attn_weights = self.softmax(attn_score_masked)\n",
    "        # applying dropout\n",
    "        attn_weights_with_dropout = self.dropout(attn_weights)\n",
    "        # multiplying with V\n",
    "        A = torch.matmul(attn_weights_with_dropout, V_head)\n",
    "        # concatenation of the vector\n",
    "        concate_heads = torch.reshape(torch.permute(A, dims = (1, 0, 2)), shape = (seq_len, self.dmodel))\n",
    "        return self.w_o(concate_heads)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a791ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MHA = MultiHeadAttention(h = 4, dmodel= 512, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9210d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = 10\n",
    "features = 512\n",
    "\n",
    "X = torch.randn(sentences, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d99846f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ff3574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHA.forward(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f788ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cba9dcfe",
   "metadata": {},
   "source": [
    "## Transformer Block Complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a85937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97d6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.d_model = d_model\n",
    "        assert self.d_model % self.heads == 0, \"Choose Correct Head Number\"\n",
    "        self.dk = self.d_model // self.heads\n",
    "        # defining dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # defining softmax\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        # query_weight, key_weight, value_weight\n",
    "        self.weight_query = nn.Linear(self.d_model, self.d_model)\n",
    "        self.weight_key = nn.Linear(self.d_model, self.d_model)\n",
    "        self.weight_value = nn.Linear(self.d_model, self.d_model)\n",
    "        self.w_o = nn.Linear(self.d_model, self.d_model)\n",
    "        self.ffn1 = nn.Linear(self.d_model, self.d_model*4)\n",
    "        self.ffn2 = nn.Linear(self.d_model*4, self.d_model)\n",
    "        self.layer_norm_1 = nn.LayerNorm(self.d_model)\n",
    "        self.layer_norm_2 = nn.LayerNorm(self.d_model)\n",
    "        # define activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # extract shape of seq_len\n",
    "        seq_len = X.shape[1]\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        ##layer normalization\n",
    "        layer_norm1_output = self.layer_norm_1(X)\n",
    "\n",
    "        #project X (B, SEQ_LEN, Dmodel) into (B, Dmodel, Dmodel)\n",
    "        Q = self.weight_query(layer_norm1_output)\n",
    "        K = self.weight_key(layer_norm1_output)\n",
    "        V = self.weight_value(layer_norm1_output)\n",
    "        Q_heads = torch.permute(torch.reshape(Q, shape = (batch_size, seq_len, self.heads, self.dk)), dims = (0, 2, 1,3))\n",
    "        K_heads = torch.permute(torch.reshape(K, shape = (batch_size, seq_len, self.heads, self.dk)), dims = (0, 2, 1,3))\n",
    "        V_heads = torch.permute(torch.reshape(V, shape = (batch_size, seq_len, self.heads, self.dk)), dims = (0, 2, 1,3))\n",
    "\n",
    "        # calculate attn score and scale\n",
    "        attn_score = (torch.matmul(Q_heads, K_heads.transpose(-1, -2)))/(math.sqrt(self.dk))\n",
    "\n",
    "        # masking \n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "        # applying mask\n",
    "        attn_score_with_mask = attn_score.masked_fill(mask.bool(), -torch.inf)\n",
    "        # applying softmax\n",
    "        attn_weight_with_mask = self.softmax(attn_score_with_mask)\n",
    "        # apply dropouts \n",
    "        attn_wgts_mask_drpt = self.dropout(attn_weight_with_mask)\n",
    "\n",
    "        ### multiply with V_heads\n",
    "        A = torch.matmul(attn_wgts_mask_drpt, V_heads)\n",
    "        ## concatenation\n",
    "        concat_A = torch.reshape(torch.permute(A, dims = (0,2,1,3)), shape = (batch_size, seq_len, self.d_model))\n",
    "        output_masked_attn = self.w_o(concat_A)\n",
    "        #return layer_norm1_output\n",
    "\n",
    "        # residual connection 1\n",
    "        residual_connection_1 = X + output_masked_attn\n",
    "\n",
    "        #layer norm 2\n",
    "        layer_norm_2_output =self.layer_norm_2(residual_connection_1)\n",
    "        # ffnn\n",
    "        ffn1 = self.ffn1(layer_norm_2_output)\n",
    "        # activation\n",
    "        activation = self.relu(ffn1)\n",
    "        # final layer\n",
    "        ffn2 = self.ffn2(activation)\n",
    "        \n",
    "        # residual connection 2\n",
    "        final_output = layer_norm_2_output + ffn2\n",
    "\n",
    "        #return the fnal vector\n",
    "        return final_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1f2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = TransformerBlock(heads = 8, d_model=512, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73bdf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(32, 20, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdb4baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.5563e-02,  1.4333e+00, -1.6501e+00,  ...,  1.3692e+00,\n",
       "           1.7790e+00,  1.5419e-01],\n",
       "         [-1.2688e+00,  1.3711e+00, -1.1390e+00,  ..., -6.4300e-01,\n",
       "          -8.2388e-01,  3.6798e-01],\n",
       "         [-1.3032e+00, -1.1401e-02,  2.5159e-01,  ...,  1.4954e+00,\n",
       "           7.1369e-01,  9.5313e-03],\n",
       "         ...,\n",
       "         [ 1.8574e-01,  1.4225e+00,  1.0207e+00,  ...,  1.0022e+00,\n",
       "          -5.7860e-02, -3.5444e-02],\n",
       "         [-2.4432e+00, -1.0321e+00,  8.7815e-01,  ...,  1.4494e+00,\n",
       "           3.3746e-01,  6.7837e-01],\n",
       "         [-4.7686e-03, -1.8188e-01,  9.3257e-02,  ..., -6.7405e-01,\n",
       "          -4.3429e-03, -1.0248e+00]],\n",
       "\n",
       "        [[ 4.3783e-01,  2.6260e-01,  5.4969e-01,  ..., -9.9060e-01,\n",
       "          -6.9231e-01,  7.0725e-01],\n",
       "         [-3.2725e-01, -1.5383e+00,  3.0135e-01,  ...,  8.6273e-01,\n",
       "           4.0771e-02, -2.9588e+00],\n",
       "         [ 9.5258e-01,  8.3034e-01,  1.3435e+00,  ...,  7.9139e-01,\n",
       "           1.7850e+00,  7.1305e-01],\n",
       "         ...,\n",
       "         [-5.2161e-02,  9.8660e-01, -2.2269e+00,  ..., -1.0302e+00,\n",
       "           2.6950e-01, -6.6603e-01],\n",
       "         [ 3.9440e-01, -4.3875e-01, -3.9013e-01,  ..., -1.2704e-01,\n",
       "          -8.3617e-01, -1.2088e+00],\n",
       "         [-1.8621e+00, -1.1688e+00, -4.7575e-01,  ..., -4.9853e-01,\n",
       "          -1.4002e+00, -9.1976e-01]],\n",
       "\n",
       "        [[ 6.6064e-01, -1.7459e+00,  1.6372e-01,  ...,  1.9023e-01,\n",
       "          -1.2000e-01, -1.1012e-01],\n",
       "         [-1.4458e-01, -1.3441e+00,  5.1436e-01,  ...,  3.2521e-01,\n",
       "          -6.5598e-01, -5.7353e-01],\n",
       "         [ 9.5070e-01, -5.7671e-01,  4.5478e-01,  ...,  1.7323e-02,\n",
       "          -1.4117e+00,  1.7584e-01],\n",
       "         ...,\n",
       "         [ 1.3885e-01, -1.4907e+00, -3.4487e-01,  ...,  4.9726e-01,\n",
       "           1.6771e-01, -4.2660e-01],\n",
       "         [-7.5646e-01,  6.9899e-01, -8.3214e-01,  ..., -2.0634e+00,\n",
       "           3.5923e-01,  1.3550e+00],\n",
       "         [ 1.0556e-01, -9.1636e-01, -1.7952e+00,  ...,  1.4558e+00,\n",
       "          -1.1968e-01,  6.9151e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.8335e-01, -8.1643e-01, -6.1507e-01,  ...,  1.4965e+00,\n",
       "           1.0652e+00,  1.9535e+00],\n",
       "         [-1.1373e+00, -6.0422e-01, -1.2823e+00,  ..., -1.2865e-01,\n",
       "          -2.9828e-01,  1.8422e+00],\n",
       "         [ 3.1053e+00,  9.7492e-01,  1.2814e+00,  ..., -4.6760e-01,\n",
       "          -1.4909e+00, -1.0995e+00],\n",
       "         ...,\n",
       "         [ 7.4293e-01, -2.3032e-01, -1.5748e+00,  ...,  6.1300e-02,\n",
       "          -1.2100e+00,  1.0611e+00],\n",
       "         [ 4.4842e-01, -1.8085e+00, -3.1574e-01,  ...,  6.2000e-01,\n",
       "          -6.5217e-01,  1.1461e+00],\n",
       "         [-7.0200e-01,  1.1006e+00,  1.5310e-01,  ...,  2.3344e-01,\n",
       "           1.0952e+00,  9.5472e-01]],\n",
       "\n",
       "        [[ 7.5109e-01, -1.2080e+00, -8.1438e-01,  ..., -5.0054e-01,\n",
       "           4.7830e-01, -8.9267e-01],\n",
       "         [ 1.2930e+00,  4.3636e-01, -1.9837e-01,  ..., -5.7725e-01,\n",
       "          -5.1460e-01, -1.8727e+00],\n",
       "         [ 1.1331e+00,  1.2783e+00,  1.2241e+00,  ..., -1.4860e+00,\n",
       "           5.8611e-01, -1.9487e-01],\n",
       "         ...,\n",
       "         [ 2.6439e-01,  2.0200e-01, -8.1861e-01,  ..., -1.6783e+00,\n",
       "           3.6562e-01,  1.4502e+00],\n",
       "         [ 1.1394e+00,  1.4551e-01, -1.8180e+00,  ..., -1.3537e+00,\n",
       "          -4.9099e-01, -1.9959e+00],\n",
       "         [ 3.7422e-01, -1.9400e+00,  8.6579e-03,  ...,  1.8893e-01,\n",
       "           2.2329e-01, -2.1684e+00]],\n",
       "\n",
       "        [[-1.4544e+00,  8.3323e-01, -1.7581e+00,  ..., -2.9925e-01,\n",
       "          -1.8063e+00, -1.7646e-02],\n",
       "         [-5.6129e-01,  4.0189e-01, -4.8069e-01,  ..., -9.7938e-01,\n",
       "          -7.8235e-01, -4.6440e-01],\n",
       "         [ 1.7771e+00,  3.5662e-01, -7.3130e-01,  ..., -7.3142e-01,\n",
       "          -2.6558e-01, -4.1805e-01],\n",
       "         ...,\n",
       "         [ 4.8742e-01, -8.4062e-01, -1.2605e+00,  ..., -4.1800e-01,\n",
       "          -5.0364e-01, -6.4641e-02],\n",
       "         [-4.0531e-01, -2.0790e-02,  6.6630e-01,  ..., -1.4454e+00,\n",
       "          -1.0637e+00,  2.7410e+00],\n",
       "         [ 3.7930e-02,  2.6973e-03, -7.9383e-01,  ...,  1.2744e-01,\n",
       "           4.8387e-01,  8.6824e-02]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d784cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class for PointWIseFeedForward Neural Network\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    \"Implements Point Wise Feedforward Neural Network\"\n",
    "    def __init__(self, d_model, dffn, dropout):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #defining layers\n",
    "        self.w_1 = nn.Linear(d_model, dffn)\n",
    "        self.w_2 = nn.Linear(dffn, d_model)\n",
    "\n",
    "        # defining forward function\n",
    "        def forward(self, X):\n",
    "            return self.dropout(self.w_2_2(nn.ReLU(self.w_1(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf54805",
   "metadata": {},
   "source": [
    "## Positional Encoding Implementation -  sin, cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afae4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "\n",
    "def sin(pos, i):\n",
    "        return math.sin(pos/10000**(2*i/d_model))\n",
    "\n",
    "def cos(pos, i):\n",
    "        return math.cos(pos/10000**(2*i/d_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e517fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "random_embeddings = torch.randn(seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9919af70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "          1.0366e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "          2.0733e-04,  1.0000e+00],\n",
       "        ...,\n",
       "        [-9.6140e-01, -2.7516e-01, -6.3753e-01,  ...,  1.0000e+00,\n",
       "          1.7623e-03,  1.0000e+00],\n",
       "        [-7.5099e-01,  6.6032e-01, -9.9638e-01,  ...,  1.0000e+00,\n",
       "          1.8659e-03,  1.0000e+00],\n",
       "        [ 1.4988e-01,  9.8870e-01, -4.9773e-01,  ...,  1.0000e+00,\n",
       "          1.9696e-03,  1.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postional_encoding_vector = []\n",
    "\n",
    "for pos in range(seq_len):\n",
    "    temp = []\n",
    "    for i in range(d_model//2):\n",
    "            temp.append(sin(pos,i))\n",
    "            temp.append(cos(pos,i))\n",
    "\n",
    "    postional_encoding_vector.append(temp)\n",
    "\n",
    "postional_encoding_vector = torch.tensor(postional_encoding_vector)\n",
    "\n",
    "postional_encoding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c71565",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional = [[sin(pos,i), cos(pos,i)] for i in range(d_model//2) for pos in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514057db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5120, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(positional).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10288a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement positional encoding using torch\n",
    "\n",
    "import math\n",
    "\n",
    "class PositionalEncoding:\n",
    "    def __init__(self, seq_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def sin(self, pos, i):\n",
    "        return math.sin(pos/10000**(2*i/self.d_model))\n",
    "    \n",
    "    def cos(self, pos, i):\n",
    "        return math.cos(pos/10000**(2*i/self.d_model))\n",
    "    \n",
    "    def calculate_pe(self):\n",
    "        positional_encoding_vector = []\n",
    "        for pos in range(self.seq_len):\n",
    "            temp = []\n",
    "            for i in range(self.d_model//2):\n",
    "                    temp.append(sin(pos,i))\n",
    "                    temp.append(cos(pos,i))\n",
    "            positional_encoding_vector.append(temp)\n",
    "        return torch.tensor(positional_encoding_vector)\n",
    "        \n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f93346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.positional_encoding import PositionalEncoding\n",
    "\n",
    "pe = PositionalEncoding(seq_len=1024, d_model=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6422eabf",
   "metadata": {},
   "source": [
    "## Decoder full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fa82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class of full transfprmer block\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from model.positional_encoding import PositionalEncoding\n",
    "from model.transformer_block import TransformerBlock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8dcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model, h, dropout, blocks, vocab_size):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        self.vocab_size = vocab_size\n",
    "        self.layernorm = nn.LayerNorm(self.d_model)\n",
    "        self.linear = nn.Linear(self.d_model, self.vocab_size)\n",
    "        self.dropout = dropout\n",
    "        self.blocks = blocks\n",
    "        # defining transformer blocks\n",
    "        self.blocks_list = nn.ModuleList()\n",
    "        for i in range(self.blocks):\n",
    "            self.blocks_list.append(TransformerBlock(heads = self.h, d_model= d_model, dropout=self.dropout))\n",
    "        # positional encoding \n",
    "        self.positional_encoding = PositionalEncoding(d_model = self.d_model)\n",
    "\n",
    "\n",
    "    # forward, assuming X (B, Seq_len, d_model)\n",
    "    def forward(self, X):\n",
    "        seq_len = X.shape[1]\n",
    "        d_model = X.shape[-1]\n",
    "        pe = self.positional_encoding.calculate_pe(X)\n",
    "        # modifying input tensor by adding X + positional encoding\n",
    "        input_tensor = X + pe\n",
    "        # this input will go into 6 transformer blocks\n",
    "        ## here also I will need to put them automatically\n",
    "        x = input_tensor.clone()\n",
    "        for block in self.blocks_list:\n",
    "            y = block(x)\n",
    "            x = y        \n",
    "        # adding layer norm 1 \n",
    "        layer_norm_1 = self.layernorm(x)\n",
    "\n",
    "        # adding linear layer\n",
    "        linear_layer_output = self.linear(layer_norm_1)\n",
    "        # returning final layer output\n",
    "        return linear_layer_output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0990a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TransformerDecoder(d_model= 512, h = 8, dropout=0.1, vocab_size=50247, blocks = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd1161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(32, 20, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44ef934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 50247])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.forward(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c592d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.decoder import TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d1e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "decdr = TransformerDecoder(d_model=512, h = 8, dropout=0.2, blocks=6,vocab_size=50247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3c7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = torch.randn(64, 121, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d360d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 121, 50247])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decdr.forward(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4f84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3468e101",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52204e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f24a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50247\n",
    "d_model = 512\n",
    "\n",
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50219b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor([[1, 2, 4], [0, 9, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d4acd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8605dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "086aafb6",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595c9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9922589",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_tokenizer = CharTokenizer(file = r\"C:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\data\\tiny-shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accf3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_list = character_tokenizer.encode(file_path= \"testing.txt\")[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cfd16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 63, 1, 52, 39]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a203c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = character_tokenizer.decode(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef6a778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My na'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6664e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a48272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f6fc3c8",
   "metadata": {},
   "source": [
    "## Dataset Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24504c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.dataset import CustomTextData\n",
    "from utils.tokenizer import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651e3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the entire file\n",
    "\n",
    "with open(r\"C:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\data\\tiny-shakespeare.txt\") as f:\n",
    "    full_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e31efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac426cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1116e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = full_text[:int((0.9)*N)]\n",
    "val_text = full_text[int((0.9)*N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecf6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing tokenizer\n",
    "tokenizer = CharTokenizer(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb223f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom = CustomTextData(text=train_text, tokenizer=tokenizer, seq_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448e6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_custom = CustomTextData(text=val_text, tokenizer=tokenizer, seq_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc7fc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_custom, batch_size=4, shuffle = True)\n",
    "val_loader = DataLoader(val_custom, batch_size=4, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "860a34ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set has data instances of 1003834\n",
      "Testing Set has data instances of 111520\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set has data instances of {len(train_custom)}\")\n",
    "print(f\"Testing Set has data instances of {len(val_custom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce075b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1505813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e8c5314",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac67cf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     74\u001b[39m loss.backward()\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# update parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# bookkeeping\u001b[39;00m\n\u001b[32m     80\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:537\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    535\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --------------------------------\n",
    "# 1. Device\n",
    "# --------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --------------------------------\n",
    "# 2. Hyperparameters\n",
    "# --------------------------------\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "d_model = 512\n",
    "\n",
    "# --------------------------------\n",
    "# 3. Vocabulary size\n",
    "# --------------------------------\n",
    "vocab_size = len(tokenizer.stoi)\n",
    "\n",
    "# --------------------------------\n",
    "# 4. Model\n",
    "# --------------------------------\n",
    "from model.decoder import TransformerDecoder\n",
    "\n",
    "model = TransformerDecoder(\n",
    "    d_model=d_model,\n",
    "    h=8,\n",
    "    dropout=0.1,\n",
    "    blocks=6,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "# --------------------------------\n",
    "# 5. Loss & Optimizer\n",
    "# --------------------------------\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# --------------------------------\n",
    "# 6. Training loop\n",
    "# --------------------------------\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        # move data to device\n",
    "        x = x.to(device)   # (B, T)\n",
    "        y = y.to(device)   # (B, T)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        logits = model.forward(x)  # (B, T, vocab_size)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fn(\n",
    "            logits.view(-1, vocab_size),\n",
    "            y.view(-1)\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # bookkeeping\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Training Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949008e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b65ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.decoder import TransformerDecoder\n",
    "\n",
    "model = TransformerDecoder(\n",
    "    d_model=512,\n",
    "    h=8,\n",
    "    dropout=0.1,\n",
    "    blocks=6,\n",
    "    vocab_size=65\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb84a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abbf6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18981953"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a775434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c39c9911",
   "metadata": {},
   "source": [
    "## Training - Device Agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121ec91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model device: cpu\n",
      "[Epoch 1] Batch 1/501917 | Loss 4.3881 | Batch time 0.23s | Epoch time 0.4s\n",
      "[Epoch 1] Batch 2/501917 | Loss 3.8391 | Batch time 0.14s | Epoch time 0.5s\n",
      "[Epoch 1] Batch 3/501917 | Loss 4.6828 | Batch time 0.15s | Epoch time 0.7s\n",
      "[Epoch 1] Batch 4/501917 | Loss 4.3010 | Batch time 0.15s | Epoch time 0.8s\n",
      "[Epoch 1] Batch 5/501917 | Loss 4.5986 | Batch time 0.15s | Epoch time 1.0s\n",
      "[Epoch 1] Batch 6/501917 | Loss 3.6799 | Batch time 0.14s | Epoch time 1.1s\n",
      "[Epoch 1] Batch 7/501917 | Loss 3.6179 | Batch time 0.14s | Epoch time 1.3s\n",
      "[Epoch 1] Batch 8/501917 | Loss 3.9406 | Batch time 0.15s | Epoch time 1.4s\n",
      "[Epoch 1] Batch 9/501917 | Loss 4.1029 | Batch time 0.14s | Epoch time 1.5s\n",
      "[Epoch 1] Batch 10/501917 | Loss 3.8688 | Batch time 0.15s | Epoch time 1.7s\n",
      "[Epoch 1] Batch 11/501917 | Loss 3.3396 | Batch time 0.16s | Epoch time 1.9s\n",
      "[Epoch 1] Batch 12/501917 | Loss 4.2421 | Batch time 0.17s | Epoch time 2.0s\n",
      "[Epoch 1] Batch 13/501917 | Loss 3.7271 | Batch time 0.19s | Epoch time 2.2s\n",
      "[Epoch 1] Batch 14/501917 | Loss 3.5470 | Batch time 0.17s | Epoch time 2.4s\n",
      "[Epoch 1] Batch 15/501917 | Loss 3.5714 | Batch time 0.16s | Epoch time 2.6s\n",
      "[Epoch 1] Batch 16/501917 | Loss 3.7465 | Batch time 0.16s | Epoch time 2.7s\n",
      "[Epoch 1] Batch 17/501917 | Loss 3.4128 | Batch time 0.16s | Epoch time 2.9s\n",
      "[Epoch 1] Batch 18/501917 | Loss 3.5443 | Batch time 0.16s | Epoch time 3.0s\n",
      "[Epoch 1] Batch 19/501917 | Loss 3.8398 | Batch time 0.16s | Epoch time 3.2s\n",
      "[Epoch 1] Batch 20/501917 | Loss 3.6319 | Batch time 0.17s | Epoch time 3.4s\n",
      "[Epoch 1] Batch 21/501917 | Loss 4.0084 | Batch time 0.17s | Epoch time 3.6s\n",
      "[Epoch 1] Batch 22/501917 | Loss 3.3535 | Batch time 0.17s | Epoch time 3.7s\n",
      "[Epoch 1] Batch 23/501917 | Loss 3.5888 | Batch time 0.15s | Epoch time 3.9s\n",
      "[Epoch 1] Batch 24/501917 | Loss 3.4446 | Batch time 0.16s | Epoch time 4.0s\n",
      "[Epoch 1] Batch 25/501917 | Loss 3.5551 | Batch time 0.15s | Epoch time 4.2s\n",
      "[Epoch 1] Batch 26/501917 | Loss 4.2145 | Batch time 0.17s | Epoch time 4.4s\n",
      "[Epoch 1] Batch 27/501917 | Loss 3.8451 | Batch time 0.18s | Epoch time 4.5s\n",
      "[Epoch 1] Batch 28/501917 | Loss 3.5099 | Batch time 0.16s | Epoch time 4.7s\n",
      "[Epoch 1] Batch 29/501917 | Loss 3.3876 | Batch time 0.16s | Epoch time 4.9s\n",
      "[Epoch 1] Batch 30/501917 | Loss 3.4044 | Batch time 0.16s | Epoch time 5.0s\n",
      "[Epoch 1] Batch 31/501917 | Loss 3.3651 | Batch time 0.15s | Epoch time 5.2s\n",
      "[Epoch 1] Batch 32/501917 | Loss 3.4222 | Batch time 0.16s | Epoch time 5.3s\n",
      "[Epoch 1] Batch 33/501917 | Loss 4.3369 | Batch time 0.17s | Epoch time 5.5s\n",
      "[Epoch 1] Batch 34/501917 | Loss 3.5340 | Batch time 0.18s | Epoch time 5.7s\n",
      "[Epoch 1] Batch 35/501917 | Loss 3.3960 | Batch time 0.18s | Epoch time 5.9s\n",
      "[Epoch 1] Batch 36/501917 | Loss 3.6604 | Batch time 0.17s | Epoch time 6.0s\n",
      "[Epoch 1] Batch 37/501917 | Loss 3.2984 | Batch time 0.16s | Epoch time 6.2s\n",
      "[Epoch 1] Batch 38/501917 | Loss 3.7071 | Batch time 0.16s | Epoch time 6.4s\n",
      "[Epoch 1] Batch 39/501917 | Loss 3.2647 | Batch time 0.15s | Epoch time 6.5s\n",
      "[Epoch 1] Batch 40/501917 | Loss 3.5285 | Batch time 0.16s | Epoch time 6.7s\n",
      "[Epoch 1] Batch 41/501917 | Loss 2.9748 | Batch time 0.17s | Epoch time 6.9s\n",
      "[Epoch 1] Batch 42/501917 | Loss 3.7843 | Batch time 0.16s | Epoch time 7.0s\n",
      "[Epoch 1] Batch 43/501917 | Loss 3.2540 | Batch time 0.14s | Epoch time 7.2s\n",
      "[Epoch 1] Batch 44/501917 | Loss 3.2059 | Batch time 0.15s | Epoch time 7.3s\n",
      "[Epoch 1] Batch 45/501917 | Loss 3.5553 | Batch time 0.15s | Epoch time 7.5s\n",
      "[Epoch 1] Batch 46/501917 | Loss 3.0451 | Batch time 0.15s | Epoch time 7.6s\n",
      "[Epoch 1] Batch 47/501917 | Loss 3.7721 | Batch time 0.15s | Epoch time 7.8s\n",
      "[Epoch 1] Batch 48/501917 | Loss 3.4143 | Batch time 0.16s | Epoch time 8.0s\n",
      "[Epoch 1] Batch 49/501917 | Loss 3.0953 | Batch time 0.18s | Epoch time 8.1s\n",
      "[Epoch 1] Batch 50/501917 | Loss 3.5187 | Batch time 0.17s | Epoch time 8.3s\n",
      "[Epoch 1] Batch 51/501917 | Loss 3.3553 | Batch time 0.15s | Epoch time 8.5s\n",
      "[Epoch 1] Batch 52/501917 | Loss 3.1677 | Batch time 0.15s | Epoch time 8.6s\n",
      "[Epoch 1] Batch 53/501917 | Loss 3.0063 | Batch time 0.17s | Epoch time 8.8s\n",
      "[Epoch 1] Batch 54/501917 | Loss 4.2681 | Batch time 0.18s | Epoch time 9.0s\n",
      "[Epoch 1] Batch 55/501917 | Loss 3.2533 | Batch time 0.17s | Epoch time 9.1s\n",
      "[Epoch 1] Batch 56/501917 | Loss 3.3303 | Batch time 0.20s | Epoch time 9.3s\n",
      "[Epoch 1] Batch 57/501917 | Loss 3.1313 | Batch time 0.16s | Epoch time 9.5s\n",
      "[Epoch 1] Batch 58/501917 | Loss 4.1699 | Batch time 0.21s | Epoch time 9.7s\n",
      "[Epoch 1] Batch 59/501917 | Loss 3.5175 | Batch time 0.22s | Epoch time 9.9s\n",
      "[Epoch 1] Batch 60/501917 | Loss 3.2999 | Batch time 0.22s | Epoch time 10.2s\n",
      "[Epoch 1] Batch 61/501917 | Loss 3.9714 | Batch time 0.22s | Epoch time 10.4s\n",
      "[Epoch 1] Batch 62/501917 | Loss 3.2026 | Batch time 0.21s | Epoch time 10.6s\n",
      "[Epoch 1] Batch 63/501917 | Loss 3.6711 | Batch time 0.20s | Epoch time 10.8s\n",
      "[Epoch 1] Batch 64/501917 | Loss 3.2962 | Batch time 0.20s | Epoch time 11.0s\n",
      "[Epoch 1] Batch 65/501917 | Loss 3.3261 | Batch time 0.20s | Epoch time 11.2s\n",
      "[Epoch 1] Batch 66/501917 | Loss 3.4627 | Batch time 0.35s | Epoch time 11.6s\n",
      "[Epoch 1] Batch 67/501917 | Loss 3.2287 | Batch time 0.24s | Epoch time 11.8s\n",
      "[Epoch 1] Batch 68/501917 | Loss 2.9989 | Batch time 0.48s | Epoch time 12.3s\n",
      "[Epoch 1] Batch 69/501917 | Loss 3.0302 | Batch time 0.23s | Epoch time 12.5s\n",
      "[Epoch 1] Batch 70/501917 | Loss 3.2903 | Batch time 0.23s | Epoch time 12.7s\n",
      "[Epoch 1] Batch 71/501917 | Loss 3.4924 | Batch time 0.28s | Epoch time 13.0s\n",
      "[Epoch 1] Batch 72/501917 | Loss 3.4040 | Batch time 0.27s | Epoch time 13.3s\n",
      "[Epoch 1] Batch 73/501917 | Loss 3.5770 | Batch time 0.22s | Epoch time 13.5s\n",
      "[Epoch 1] Batch 74/501917 | Loss 3.3864 | Batch time 0.20s | Epoch time 13.7s\n",
      "[Epoch 1] Batch 75/501917 | Loss 3.4843 | Batch time 0.21s | Epoch time 13.9s\n",
      "[Epoch 1] Batch 76/501917 | Loss 3.1618 | Batch time 0.28s | Epoch time 14.2s\n",
      "[Epoch 1] Batch 77/501917 | Loss 3.8998 | Batch time 0.21s | Epoch time 14.4s\n",
      "[Epoch 1] Batch 78/501917 | Loss 3.4237 | Batch time 0.24s | Epoch time 14.7s\n",
      "[Epoch 1] Batch 79/501917 | Loss 3.6449 | Batch time 0.21s | Epoch time 14.9s\n",
      "[Epoch 1] Batch 80/501917 | Loss 3.4228 | Batch time 0.24s | Epoch time 15.1s\n",
      "[Epoch 1] Batch 81/501917 | Loss 3.1180 | Batch time 0.22s | Epoch time 15.3s\n",
      "[Epoch 1] Batch 82/501917 | Loss 3.6255 | Batch time 0.20s | Epoch time 15.5s\n",
      "[Epoch 1] Batch 83/501917 | Loss 3.2123 | Batch time 0.20s | Epoch time 15.7s\n",
      "[Epoch 1] Batch 84/501917 | Loss 3.3336 | Batch time 0.19s | Epoch time 15.9s\n",
      "[Epoch 1] Batch 85/501917 | Loss 3.0258 | Batch time 0.20s | Epoch time 16.1s\n",
      "[Epoch 1] Batch 86/501917 | Loss 3.2518 | Batch time 0.17s | Epoch time 16.3s\n",
      "[Epoch 1] Batch 87/501917 | Loss 3.2039 | Batch time 0.22s | Epoch time 16.5s\n",
      "[Epoch 1] Batch 88/501917 | Loss 3.2631 | Batch time 0.19s | Epoch time 16.7s\n",
      "[Epoch 1] Batch 89/501917 | Loss 3.2719 | Batch time 0.20s | Epoch time 16.9s\n",
      "[Epoch 1] Batch 90/501917 | Loss 3.3711 | Batch time 0.21s | Epoch time 17.1s\n",
      "[Epoch 1] Batch 91/501917 | Loss 3.7542 | Batch time 0.20s | Epoch time 17.3s\n",
      "[Epoch 1] Batch 92/501917 | Loss 3.2976 | Batch time 0.19s | Epoch time 17.5s\n",
      "[Epoch 1] Batch 93/501917 | Loss 3.2750 | Batch time 0.25s | Epoch time 17.8s\n",
      "[Epoch 1] Batch 94/501917 | Loss 3.0500 | Batch time 0.19s | Epoch time 18.0s\n",
      "[Epoch 1] Batch 95/501917 | Loss 3.7343 | Batch time 0.22s | Epoch time 18.2s\n",
      "[Epoch 1] Batch 96/501917 | Loss 3.8701 | Batch time 0.22s | Epoch time 18.4s\n",
      "[Epoch 1] Batch 97/501917 | Loss 3.0055 | Batch time 0.23s | Epoch time 18.7s\n",
      "[Epoch 1] Batch 98/501917 | Loss 3.4085 | Batch time 0.25s | Epoch time 18.9s\n",
      "[Epoch 1] Batch 99/501917 | Loss 3.6597 | Batch time 0.24s | Epoch time 19.2s\n",
      "[Epoch 1] Batch 100/501917 | Loss 3.7277 | Batch time 0.23s | Epoch time 19.4s\n",
      "[Epoch 1] Batch 101/501917 | Loss 3.0662 | Batch time 0.24s | Epoch time 19.6s\n",
      "[Epoch 1] Batch 102/501917 | Loss 3.0240 | Batch time 0.21s | Epoch time 19.8s\n",
      "[Epoch 1] Batch 103/501917 | Loss 3.3707 | Batch time 0.25s | Epoch time 20.1s\n",
      "[Epoch 1] Batch 104/501917 | Loss 4.0562 | Batch time 0.23s | Epoch time 20.3s\n",
      "[Epoch 1] Batch 105/501917 | Loss 3.2034 | Batch time 0.24s | Epoch time 20.6s\n",
      "[Epoch 1] Batch 106/501917 | Loss 3.1920 | Batch time 0.23s | Epoch time 20.8s\n",
      "[Epoch 1] Batch 107/501917 | Loss 3.3876 | Batch time 0.25s | Epoch time 21.1s\n",
      "[Epoch 1] Batch 108/501917 | Loss 3.3005 | Batch time 0.22s | Epoch time 21.3s\n",
      "[Epoch 1] Batch 109/501917 | Loss 3.3355 | Batch time 0.27s | Epoch time 21.6s\n",
      "[Epoch 1] Batch 110/501917 | Loss 3.5315 | Batch time 0.22s | Epoch time 21.8s\n",
      "[Epoch 1] Batch 111/501917 | Loss 3.3931 | Batch time 0.22s | Epoch time 22.0s\n",
      "[Epoch 1] Batch 112/501917 | Loss 3.1797 | Batch time 0.23s | Epoch time 22.3s\n",
      "[Epoch 1] Batch 113/501917 | Loss 3.2207 | Batch time 0.25s | Epoch time 22.5s\n",
      "[Epoch 1] Batch 114/501917 | Loss 3.8883 | Batch time 0.26s | Epoch time 22.8s\n",
      "[Epoch 1] Batch 115/501917 | Loss 3.3100 | Batch time 0.24s | Epoch time 23.0s\n",
      "[Epoch 1] Batch 116/501917 | Loss 3.2482 | Batch time 0.25s | Epoch time 23.3s\n",
      "[Epoch 1] Batch 117/501917 | Loss 3.1598 | Batch time 0.25s | Epoch time 23.5s\n",
      "[Epoch 1] Batch 118/501917 | Loss 3.3975 | Batch time 0.27s | Epoch time 23.8s\n",
      "[Epoch 1] Batch 119/501917 | Loss 3.0891 | Batch time 0.25s | Epoch time 24.0s\n",
      "[Epoch 1] Batch 120/501917 | Loss 3.0143 | Batch time 0.23s | Epoch time 24.3s\n",
      "[Epoch 1] Batch 121/501917 | Loss 3.1549 | Batch time 0.21s | Epoch time 24.5s\n",
      "[Epoch 1] Batch 122/501917 | Loss 3.9323 | Batch time 0.22s | Epoch time 24.7s\n",
      "[Epoch 1] Batch 123/501917 | Loss 3.3702 | Batch time 0.22s | Epoch time 24.9s\n",
      "[Epoch 1] Batch 124/501917 | Loss 3.6781 | Batch time 0.24s | Epoch time 25.2s\n",
      "[Epoch 1] Batch 125/501917 | Loss 3.0842 | Batch time 0.22s | Epoch time 25.4s\n",
      "[Epoch 1] Batch 126/501917 | Loss 4.4654 | Batch time 0.21s | Epoch time 25.6s\n",
      "[Epoch 1] Batch 127/501917 | Loss 3.2912 | Batch time 0.22s | Epoch time 25.8s\n",
      "[Epoch 1] Batch 128/501917 | Loss 3.9066 | Batch time 0.21s | Epoch time 26.1s\n",
      "[Epoch 1] Batch 129/501917 | Loss 3.3682 | Batch time 0.27s | Epoch time 26.3s\n",
      "[Epoch 1] Batch 130/501917 | Loss 3.2726 | Batch time 0.27s | Epoch time 26.6s\n",
      "[Epoch 1] Batch 131/501917 | Loss 3.2349 | Batch time 0.22s | Epoch time 26.8s\n",
      "[Epoch 1] Batch 132/501917 | Loss 3.3323 | Batch time 0.21s | Epoch time 27.0s\n",
      "[Epoch 1] Batch 133/501917 | Loss 3.1746 | Batch time 0.21s | Epoch time 27.2s\n",
      "[Epoch 1] Batch 134/501917 | Loss 3.8382 | Batch time 0.25s | Epoch time 27.5s\n",
      "[Epoch 1] Batch 135/501917 | Loss 4.3857 | Batch time 0.20s | Epoch time 27.7s\n",
      "[Epoch 1] Batch 136/501917 | Loss 3.4876 | Batch time 0.20s | Epoch time 27.9s\n",
      "[Epoch 1] Batch 137/501917 | Loss 3.1900 | Batch time 0.21s | Epoch time 28.1s\n",
      "[Epoch 1] Batch 138/501917 | Loss 3.4847 | Batch time 0.23s | Epoch time 28.4s\n",
      "[Epoch 1] Batch 139/501917 | Loss 3.3886 | Batch time 0.25s | Epoch time 28.6s\n",
      "[Epoch 1] Batch 140/501917 | Loss 3.6689 | Batch time 0.21s | Epoch time 28.8s\n",
      "[Epoch 1] Batch 141/501917 | Loss 3.6035 | Batch time 0.21s | Epoch time 29.0s\n",
      "[Epoch 1] Batch 142/501917 | Loss 3.3142 | Batch time 0.23s | Epoch time 29.3s\n",
      "[Epoch 1] Batch 143/501917 | Loss 3.4006 | Batch time 0.38s | Epoch time 29.6s\n",
      "[Epoch 1] Batch 144/501917 | Loss 3.4651 | Batch time 0.32s | Epoch time 30.0s\n",
      "[Epoch 1] Batch 145/501917 | Loss 3.2716 | Batch time 0.24s | Epoch time 30.2s\n",
      "[Epoch 1] Batch 146/501917 | Loss 3.3234 | Batch time 0.25s | Epoch time 30.5s\n",
      "[Epoch 1] Batch 147/501917 | Loss 3.6041 | Batch time 0.19s | Epoch time 30.7s\n",
      "[Epoch 1] Batch 148/501917 | Loss 3.4802 | Batch time 0.17s | Epoch time 30.8s\n",
      "[Epoch 1] Batch 149/501917 | Loss 3.0275 | Batch time 0.16s | Epoch time 31.0s\n",
      "[Epoch 1] Batch 150/501917 | Loss 3.0302 | Batch time 0.17s | Epoch time 31.2s\n",
      "[Epoch 1] Batch 151/501917 | Loss 3.3029 | Batch time 0.15s | Epoch time 31.3s\n",
      "[Epoch 1] Batch 152/501917 | Loss 3.7107 | Batch time 0.16s | Epoch time 31.5s\n",
      "[Epoch 1] Batch 153/501917 | Loss 3.1754 | Batch time 0.15s | Epoch time 31.6s\n",
      "[Epoch 1] Batch 154/501917 | Loss 3.4869 | Batch time 0.16s | Epoch time 31.8s\n",
      "[Epoch 1] Batch 155/501917 | Loss 3.2120 | Batch time 0.14s | Epoch time 31.9s\n",
      "[Epoch 1] Batch 156/501917 | Loss 3.5368 | Batch time 0.15s | Epoch time 32.1s\n",
      "[Epoch 1] Batch 157/501917 | Loss 3.4293 | Batch time 0.17s | Epoch time 32.3s\n",
      "[Epoch 1] Batch 158/501917 | Loss 3.3195 | Batch time 0.15s | Epoch time 32.4s\n",
      "[Epoch 1] Batch 159/501917 | Loss 3.2683 | Batch time 0.13s | Epoch time 32.5s\n",
      "[Epoch 1] Batch 160/501917 | Loss 3.1149 | Batch time 0.14s | Epoch time 32.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m     99\u001b[39m loss = loss_fn(\n\u001b[32m    100\u001b[39m     logits.view(-\u001b[32m1\u001b[39m, vocab_size),\n\u001b[32m    101\u001b[39m     y.view(-\u001b[32m1\u001b[39m)\n\u001b[32m    102\u001b[39m )\n\u001b[32m    104\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m total_loss += loss.item()\n\u001b[32m    108\u001b[39m num_batches += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:535\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    533\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    537\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from training.dataset import CustomTextData\n",
    "from utils.tokenizer import CharTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from model.decoder import TransformerDecoder\n",
    "\n",
    "\n",
    "\n",
    "## reading the entire file\n",
    "\n",
    "with open(r\"C:\\Users\\amanm\\Desktop\\learning\\transformer_from_scratch\\data\\tiny-shakespeare.txt\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "\n",
    "N = len(full_text)\n",
    "\n",
    "\n",
    "## Splitting train and validation and data split\n",
    "\n",
    "train_text = full_text[:int((0.9)*N)]\n",
    "val_text = full_text[int((0.9)*N):]\n",
    "\n",
    "\n",
    "# preparing tokenizer\n",
    "tokenizer = CharTokenizer(train_text)\n",
    "\n",
    "train_custom = CustomTextData(text=train_text, tokenizer=tokenizer, seq_len=20)\n",
    "val_custom = CustomTextData(text=val_text, tokenizer=tokenizer, seq_len=20)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_custom, batch_size=2, shuffle = True)\n",
    "val_loader = DataLoader(val_custom, batch_size=2, shuffle = False)\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 1. Device\n",
    "# --------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, flush=True)\n",
    "\n",
    "# --------------------------------\n",
    "# 2. Hyperparameters\n",
    "# --------------------------------\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "d_model = 512\n",
    "\n",
    "# --------------------------------\n",
    "# 3. Vocabulary size\n",
    "# --------------------------------\n",
    "vocab_size = len(tokenizer.stoi)\n",
    "\n",
    "# --------------------------------\n",
    "# 4. Model\n",
    "# --------------------------------\n",
    "model = TransformerDecoder(\n",
    "    d_model=d_model,\n",
    "    h=8,\n",
    "    dropout=0.1,\n",
    "    blocks=6,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "#  Sanity check\n",
    "print(\"Model device:\", next(model.parameters()).device, flush=True)\n",
    "\n",
    "# --------------------------------\n",
    "# 5. Loss & Optimizer\n",
    "# --------------------------------\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# --------------------------------\n",
    "# 6. Training loop\n",
    "# --------------------------------\n",
    "import time\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        batch_start = time.time()\n",
    "\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "\n",
    "        loss = loss_fn(\n",
    "            logits.view(-1, vocab_size),\n",
    "            y.view(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        #  PRINT EVERY BATCH\n",
    "        print(\n",
    "            f\"[Epoch {epoch+1}] \"\n",
    "            f\"Batch {num_batches}/{len(train_loader)} | \"\n",
    "            f\"Loss {loss.item():.4f} | \"\n",
    "            f\"Batch time {time.time() - batch_start:.2f}s | \"\n",
    "            f\"Epoch time {time.time() - epoch_start:.1f}s\",\n",
    "            flush=True\n",
    "        )\n",
    "\n",
    "    avg_loss = total_loss / max(1, num_batches)\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}] DONE | \"\n",
    "        f\"Avg Loss {avg_loss:.4f} | \"\n",
    "        f\"Total Epoch Time {time.time() - epoch_start:.1f}s\",\n",
    "        flush=True\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
